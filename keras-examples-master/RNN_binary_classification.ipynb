{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import imdb\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "maxlen = 10\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3s 127us/step - loss: 0.6879 - acc: 0.5510 - val_loss: 0.6796 - val_acc: 0.5832\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 3s 128us/step - loss: 0.6456 - acc: 0.6233 - val_loss: 0.5984 - val_acc: 0.6646\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 4s 150us/step - loss: 0.5878 - acc: 0.6802 - val_loss: 0.5973 - val_acc: 0.6677s - loss: \n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 4s 179us/step - loss: 0.5548 - acc: 0.7072 - val_loss: 0.6438 - val_acc: 0.65695564 - acc:\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 4s 147us/step - loss: 0.5405 - acc: 0.7186 - val_loss: 0.5490 - val_acc: 0.7092\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 4s 153us/step - loss: 0.5304 - acc: 0.7264 - val_loss: 0.5473 - val_acc: 0.7124\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 5s 210us/step - loss: 0.5153 - acc: 0.7384 - val_loss: 0.5470 - val_acc: 0.7154\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 6s 230us/step - loss: 0.5103 - acc: 0.7413 - val_loss: 0.5467 - val_acc: 0.7131\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 5s 194us/step - loss: 0.5038 - acc: 0.7467 - val_loss: 0.5499 - val_acc: 0.7118\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 4s 151us/step - loss: 0.4987 - acc: 0.7479 - val_loss: 0.5503 - val_acc: 0.7140\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, input_length=maxlen))\n",
    "model.add(GRU(20, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "res_gru_1 = model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 10s 420us/step - loss: 0.6889 - acc: 0.5432 - val_loss: 0.6773 - val_acc: 0.5863\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 13s 505us/step - loss: 0.6340 - acc: 0.6333 - val_loss: 0.5958 - val_acc: 0.6702\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 12s 466us/step - loss: 0.5808 - acc: 0.6840 - val_loss: 0.5770 - val_acc: 0.6845\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 12s 467us/step - loss: 0.5544 - acc: 0.7080 - val_loss: 0.5584 - val_acc: 0.7016\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 9s 379us/step - loss: 0.5364 - acc: 0.7198 - val_loss: 0.5542 - val_acc: 0.7059\n",
      "Epoch 6/10\n",
      "13312/25000 [==============>...............] - ETA: 2s - loss: 0.5269 - acc: 0.7273"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, input_length=maxlen))\n",
    "model.add(GRU(20, return_sequences=True))\n",
    "model.add(GRU(20, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "res_gru_2 = model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, input_length=maxlen))\n",
    "model.add(LSTM(20, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "res_lstm_1 = model.fit(x_train, y_train, batch_size=256, epochs=epochs,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(epochs)\n",
    "plt.plot(x, res_gru_1.history['acc'], label='GRU 1 train')\n",
    "plt.plot(x, res_gru_1.history['val_acc'], label='GRU 1 val')\n",
    "plt.plot(x, res_gru_2.history['acc'], label='GRU 2 train')\n",
    "plt.plot(x, res_gru_2.history['val_acc'], label='GRU 2 val')\n",
    "plt.plot(x, res_lstm_1.history['acc'], label='LSTM train')\n",
    "plt.plot(x, res_lstm_1.history['val_acc'], label='LSTM val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, res_gru_1.history['loss'], label='GRU 1 train')\n",
    "plt.plot(x, res_gru_1.history['val_loss'], label='GRU 1 val')\n",
    "plt.plot(x, res_gru_2.history['loss'], label='GRU 2 train')\n",
    "plt.plot(x, res_gru_2.history['val_loss'], label='GRU 2 val')\n",
    "plt.plot(x, res_lstm_1.history['loss'], label='LSTM train')\n",
    "plt.plot(x, res_lstm_1.history['val_loss'], label='LSTM val')\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
